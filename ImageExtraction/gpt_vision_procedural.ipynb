{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"OpenAI API Key Here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _openai() -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\", messages=messages\n",
    "    )\n",
    "    assistant_says = response.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_says})\n",
    "    return assistant_says"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(image_url: str, instruction: str) -> str:\n",
    "    messages.clear # let's start stateless\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": instruction},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "        ]\n",
    "    })\n",
    "    return _openai()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"social_situation\": {\n",
      "    \"description\": \"A group of young adults casually socializing outdoors\",\n",
      "    \"number_of_people\": 5,\n",
      "    \"setting\": \"Outdoor, possibly urban area near a chain link fence with graffiti in the background.\",\n",
      "    \"time_of_day\": \"Likely late afternoon or early evening given the long shadows\"\n",
      "  },\n",
      "  \"people\": [\n",
      "    {\n",
      "      \"person_id\": 1,\n",
      "      \"gender\": \"Male\",\n",
      "      \"position\": \"Standing on the left\",\n",
      "      \"attire\": {\n",
      "        \"upper_body\": \"Denim jacket over a white top\",\n",
      "        \"lower_body\": \"Dark pants\",\n",
      "        \"shoes\": \"White sneakers\"\n",
      "      },\n",
      "      \"hair_color\": \"Dark\",\n",
      "      \"posture\": \"Standing with hands in pockets, slightly turned toward the left\"\n",
      "    },\n",
      "    {\n",
      "      \"person_id\": 2,\n",
      "      \"gender\": \"Male\",\n",
      "      \"position\": \"Sitting in the center\",\n",
      "      \"attire\": {\n",
      "        \"upper_body\": \"Brown jacket over a dark top\",\n",
      "        \"lower_body\": \"Light-colored pants\",\n",
      "        \"shoes\": \"White sneakers\"\n",
      "      },\n",
      "      \"hair_color\": \"Blond\",\n",
      "      \"posture\": \"Seated with one knee raised, looking up\"\n",
      "    },\n",
      "    {\n",
      "      \"person_id\": 3,\n",
      "      \"gender\": \"Male\",\n",
      "      \"position\": \"Standing in the middle\",\n",
      "      \"attire\": {\n",
      "        \"upper_body\": \"Dark and white striped long sleeve shirt\",\n",
      "        \"lower_body\": \"Dark pants\",\n",
      "        \"shoes\": \"Black shoes\"\n",
      "      },\n",
      "      \"hair_color\": \"Dark\",\n",
      "      \"posture\": \"Standing with hands clasped in front, facing slightly right\"\n",
      "    },\n",
      "    {\n",
      "      \"person_id\": 4,\n",
      "      \"gender\": \"Female\",\n",
      "      \"position\": \"Standing on the right\",\n",
      "      \"attire\": {\n",
      "        \"upper_body\": \"Sweater with a green, white and maroon chevron pattern\",\n",
      "        \"lower_body\": \"Dark pants\",\n",
      "        \"shoes\": \"Light-colored footwear\"\n",
      "      },\n",
      "      \"hair_color\": \"Dark\",\n",
      "      \"posture\": \"Standing with arms by her side, facing another person\"\n",
      "    },\n",
      "    {\n",
      "      \"person_id\": 5,\n",
      "      \"gender\": \"Female\",\n",
      "      \"position\": \"Standing on the far right\",\n",
      "      \"attire\": {\n",
      "        \"upper_body\": \"Yellow top\",\n",
      "        \"lower_body\": \"Blue jeans\",\n",
      "        \"shoes\": \"Brownish ankle boots\"\n",
      "      },\n",
      "      \"hair_color\": \"Dark\",\n",
      "      \"posture\": \"Standing with one hand on hip, engaged in conversation\"\n",
      "    }\n",
      "  ],\n",
      "  \"activity\": \"Conversing, relaxing, possibly waiting for something or someone\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result: str = extract(\n",
    "    \"https://chunntguet.xyz/pics/eliott-reyna-axTm0ee3YP4-unsplash.jpg\",\n",
    "    \"\"\"\n",
    "        Identifiy the social situation represented in this picture.\n",
    "        Recognise the people involved and give an estimate of what they are up to.\n",
    "        Include as many observations as possible that can be used to recognise the same people in other pictures.\n",
    "        Provide your detection in JSON format. \n",
    "        Return a JSON object containing meaningful attributes with values reflecting the detections from the picture.,\n",
    "    \"\"\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"presence_of_person\": \"Yes\",\n",
      "  \"person_detected\": {\n",
      "    \"person_id\": 4,\n",
      "    \"gender\": \"Female\",\n",
      "    \"position\": \"Central in frame\",\n",
      "    \"attire\": {\n",
      "      \"upper_body\": \"Sweater with a green, white and maroon chevron pattern\",\n",
      "      \"lower_body\": \"Dark pants\",\n",
      "      \"shoes\": \"Not visible in this picture\"\n",
      "    },\n",
      "    \"hair_color\": \"Dark\",\n",
      "    \"posture\": \"Standing, though no longer with arms by her side; hands are up and gesturing, suggesting an active involvement in the current social interaction\"\n",
      "  },\n",
      "  \"observations\": {\n",
      "    \"facial_expression\": \"Smiling, appearing to be enjoying the interaction\",\n",
      "    \"engagement\": \"Directly interacting with at least one other individual in a playful manner\",\n",
      "    \"additional_context\": \"Based on the previous description, attire and hair can be used as recognition parameters in other images as well.\"\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result: str = extract(\n",
    "    \"https://chunntguet.xyz/pics/eliott-reyna-5KrZ3UoDKC4-unsplash.jpg\",\n",
    "    \"\"\"\n",
    "        Check if you can spot a person in this picture.\n",
    "        Here are the details about the person to be spotted:\n",
    "        {\n",
    "            \"person_id\": 4,\n",
    "            \"gender\": \"Female\",\n",
    "            \"position\": \"Standing on the right\",\n",
    "            \"attire\": {\n",
    "                \"upper_body\": \"Sweater with a green, white and maroon chevron pattern\",\n",
    "                \"lower_body\": \"Dark pants\",\n",
    "                \"shoes\": \"Light-colored footwear\"\n",
    "            },\n",
    "            \"hair_color\": \"Dark\",\n",
    "            \"posture\": \"Standing with arms by her side, facing another person\"\n",
    "        }\n",
    "        Include as many observations as possible that can be used to recognise that person in other pictures.\n",
    "        Provide your detection in JSON format. \n",
    "        Return a JSON object containing meaningful attributes with values reflecting the detections from the picture.,\n",
    "    \"\"\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
